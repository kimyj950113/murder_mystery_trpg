# gpt_api.py
from openai import OpenAI
import streamlit as st
import json

# OpenRouterìš© OpenAI í´ë¼ì´ì–¸íŠ¸ ìƒì„±
client = OpenAI(
    api_key=st.secrets["OPENROUTER_API_KEY"],
    base_url=st.secrets["OPENROUTER_BASE_URL"]
)

def generate_scenario(theme):
    prompt = f"""
    ë¨¸ë” ë¯¸ìŠ¤í„°ë¦¬ ì‹œë‚˜ë¦¬ì˜¤ë¥¼ JSON í˜•ì‹ìœ¼ë¡œ ë§Œë“¤ì–´ì¤˜.
    - ë°°ê²½ í…Œë§ˆ: {theme}
    - ì¸ë¬¼ ìˆ˜: 4ëª…
    - ê° ì¸ë¬¼ì˜ ì´ë¦„ê³¼ ë¹„ë°€ í¬í•¨
    - ì„¤ì • ì„¤ëª…, ì¥ì†Œ ì„¤ëª…, í”¼í•´ì ì´ë¦„ í¬í•¨
    - ì¶œë ¥ì€ JSON í˜•ì‹, í‚¤ëŠ” ì˜ì–´. ì˜ˆì‹œ:

    {{
        "setting": "...",
        "victim": "...",
        "characters": [
            {{"name": "...", "secret": "..."}},
            ...
        ]
    }}
    """
    response = client.chat.completions.create(
        model="gpt-3.5-turbo",  # ë¬´ë£Œ ê³„ì • í˜¸í™˜ ëª¨ë¸
        messages=[{"role": "user", "content": prompt}],
        max_tokens=1200
    )
    return json.loads(response.choices[0].message.content)

def generate_response(user_input, session_state):
    context = "\n".join(session_state.history[-6:])
    character_name = session_state.role["name"]
    character_secret = session_state.role["secret"]
    setting = session_state.scenario['setting']
    characters = session_state.scenario['characters']

    prompt = f"""
    [ì‹œë‚˜ë¦¬ì˜¤ ì„¤ì •]
    {setting}

    [ë‹¹ì‹ ì˜ ì—­í• ]
    {character_name} - {character_secret}

    [ë“±ì¥ì¸ë¬¼ ëª©ë¡]
    {characters}

    [ì´ì „ ëŒ€í™” ê¸°ë¡]
    {context}

    [í”Œë ˆì´ì–´ì˜ ì…ë ¥]
    {user_input}

    [ì‘ë‹µ ê·œì¹™]
    - ë°˜ë“œì‹œ í•œêµ­ì–´ë¡œ ì‘ë‹µí•  ê²ƒ
    - í”Œë ˆì´ì–´ì˜ í–‰ë™ì— ëŒ€í•´ ì„œìˆ ì ìœ¼ë¡œ ë°˜ì‘
    - NPCë‚˜ ì£¼ë³€ í™˜ê²½ì„ ë§ˆìŠ¤í„°ì²˜ëŸ¼ ë¬˜ì‚¬í•  ê²ƒ
    - ìƒˆë¡œìš´ ë‹¨ì„œê°€ ìˆë‹¤ë©´ ëª…í™•íˆ ë“œëŸ¬ë‚´ê¸°

    ì§€ê¸ˆ ë°”ë¡œ ë°˜ì‘ì„ ì¶œë ¥í•˜ì„¸ìš”.
    """
    response = client.chat.completions.create(
        model="gpt-3.5-turbo",  # ë˜ëŠ” gpt-4o (ìœ ë£Œ ê³„ì •)
        messages=[{"role": "user", "content": prompt}],
        max_tokens=800
    )
    return response.choices[0].message.content.strip()

def generate_interrogation_response(target, question, session_state):
    context = "\n".join(session_state.history[-6:])
    character_name = session_state.role["name"]
    character_secret = session_state.role["secret"]
    setting = session_state.scenario['setting']
    characters = session_state.scenario['characters']

    prompt = f"""
    [ì‹œë‚˜ë¦¬ì˜¤ ì„¤ì •]
    {setting}

    [í”Œë ˆì´ì–´ ìºë¦­í„°]
    {character_name} - {character_secret}

    [ë“±ì¥ì¸ë¬¼]
    {characters}

    [ìƒí™©]
    í”Œë ˆì´ì–´ê°€ {target}ì—ê²Œ ë‹¤ìŒ ì§ˆë¬¸ì„ í•©ë‹ˆë‹¤: "{question}"

    [ì‘ë‹µ ê·œì¹™]
    - ë°˜ë“œì‹œ í•œêµ­ì–´ë¡œ ì¶œë ¥
    - {target}ì˜ ë§íˆ¬ì™€ ê°ì •ì„ ë¬˜ì‚¬
    - NPCì˜ ë¹„ë°€ì„ ì§ì ‘ ë“œëŸ¬ë‚´ì§€ ì•Šë˜ ì˜ì‹¬ì„ ìœ ë„í•  ìˆ˜ ìˆìŒ

    [ì¶œë ¥ í˜•ì‹]
    ğŸ­ {target}: "..."
    """
    response = client.chat.completions.create(
        model="gpt-3.5-turbo",
        messages=[{"role": "user", "content": prompt}],
        max_tokens=600
    )
    return response.choices[0].message.content.strip()

def evaluate_guess(guess_name, session_state):
    setting = session_state.scenario['setting']
    victim = session_state.scenario.get("victim", "í”¼í•´ì ì •ë³´ ì—†ìŒ")
    characters = session_state.scenario['characters']
    clues = session_state.clues

    prompt = f"""
    [ì‹œë‚˜ë¦¬ì˜¤ ì„¤ì •]
    {setting}

    [í”¼í•´ì]
    {victim}

    [ë“±ì¥ì¸ë¬¼ ëª©ë¡]
    {characters}

    [ìˆ˜ì§‘ëœ ë‹¨ì„œ]
    {clues}

    [í”Œë ˆì´ì–´ì˜ ìµœì¢… ì¶”ë¦¬]
    ë²”ì¸ì€ {guess_name}ì´ë¼ê³  ì§€ëª©í–ˆìŠµë‹ˆë‹¤.

    [ì‘ë‹µ ê·œì¹™]
    - í•œêµ­ì–´ë¡œ ì¶œë ¥
    - í”Œë ˆì´ì–´ì˜ ì¶”ë¦¬ê°€ ë§ëŠ”ì§€ íŒì •í•˜ê³  ì´ìœ  ì„¤ëª…
    - ì§„ì§œ ë²”ì¸ì´ ëˆ„êµ¬ì˜€ëŠ”ì§€ ë°í˜€ì£¼ì„¸ìš”

    ê²°ê³¼ë¥¼ ì•Œë ¤ì£¼ì„¸ìš”.
    """
    response = client.chat.completions.create(
        model="gpt-3.5-turbo",
        messages=[{"role": "user", "content": prompt}],
        max_tokens=800
    )
    return response.choices[0].message.content.strip()
